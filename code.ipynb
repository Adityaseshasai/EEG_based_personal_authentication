{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8ff3fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "362f0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_files=glob('C:/aditya/Research_Intership/eeg_files/files/S001/*.edf')\n",
    "# print(type(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1871d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "no_of_patients=5\n",
    "print(str('109'.zfill(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9dc3ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R04.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R05.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R06.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R07.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R08.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R09.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R10.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R04.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R05.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R06.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R07.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R08.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R09.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R10.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R04.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R05.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R06.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R07.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R08.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R09.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R10.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R04.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R05.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R06.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R07.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R08.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R09.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R10.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R04.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R05.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R06.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R07.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R08.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R09.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R10.edf']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=[]\n",
    "test=[]\n",
    "for i in range(1,no_of_patients+1):\n",
    "    files=glob('C:/aditya/Research_Intership/eeg_files/files/S'+str(str(i).zfill(3))+'/*.edf')\n",
    "    files=files[2:]\n",
    "    train+=files[:8]\n",
    "    test+=files[8:]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28753de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "76bd25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = mne.io.read_raw_edf(file_path,preload=True)\n",
    "    data.set_eeg_reference() # takes the average values of all channels and sets it as a reference. \n",
    "    data.filter(l_freq=0.5,h_freq=45) # filters out the data (lbound = 0.5Hz, ubound = 45Hz)\n",
    "    # splits the data into segments\n",
    "    epochs=mne.make_fixed_length_epochs(data,duration=5,overlap=1)\n",
    "    array=epochs.get_data() # converts it into a numpy array [mne obj ---> numpy array]\n",
    "#     data.plot()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc966842",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_data=[read_data(i) for i in train]\n",
    "test_data=[read_data(i) for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da7bf415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "383768dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "test_labels=[]\n",
    "count=1\n",
    "ic=1\n",
    "for i,j in enumerate(train_data):\n",
    "    train_labels+=[[count]*len(j)]\n",
    "    ic+=1\n",
    "    if ic==9:\n",
    "        ic=1\n",
    "        count+=1\n",
    "count=1\n",
    "for i,j in enumerate(test_data):\n",
    "    test_labels+=[[count]*len(j)]\n",
    "    ic+=1\n",
    "    if ic==5:\n",
    "        ic=1\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8b3b44b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]]\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8e116e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def mean(x):\n",
    "    return np.mean(x,axis=-1)\n",
    "\n",
    "def std(x):\n",
    "    return np.std(x,axis=-1)\n",
    "\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.var(x,axis=-1)\n",
    "\n",
    "def minim(x):\n",
    "    return np.min(x,axis=-1)\n",
    "\n",
    "def maxim(x):\n",
    "    return np.max(x,axis=-1)\n",
    "\n",
    "def argminim(x):\n",
    "    return np.argmin(x,axis=-1)\n",
    "\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x,axis=-1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt((np.mean(x**2,axis=-1)))\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x,axis=-1)),axis=-1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x,axis=-1)\n",
    "\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x,axis=-1)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    return np.concatenate((mean(x),std(x),ptp(x),var(x),minim(x),maxim(x),argminim(x),argmaxim(x),rms(x),abs_diff_signal(x),skewness(x),kurtosis(x)),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "927e4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train=[]\n",
    "for d in train_data:\n",
    "    features_train.append(concatenate_features(d))\n",
    "features_test=[]\n",
    "for d in test_data:\n",
    "    features_test.append(concatenate_features(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a727b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=np.vstack(features_train)\n",
    "testing=np.vstack(features_test)\n",
    "t_label=np.hstack(train_labels)\n",
    "test_label=np.hstack(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be677cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.89      0.68       124\n",
      "           2       0.69      0.47      0.56       120\n",
      "           3       0.98      0.95      0.97       124\n",
      "           4       0.86      0.62      0.72       120\n",
      "           5       0.73      0.71      0.72       120\n",
      "\n",
      "    accuracy                           0.73       608\n",
      "   macro avg       0.76      0.73      0.73       608\n",
      "weighted avg       0.76      0.73      0.73       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(training, t_label)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_model.predict(testing)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(test_label, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7abbf54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.30      0.30       124\n",
      "           2       0.27      0.24      0.26       120\n",
      "           3       0.33      0.34      0.33       124\n",
      "           4       0.38      0.42      0.40       120\n",
      "           5       0.28      0.27      0.27       120\n",
      "\n",
      "    accuracy                           0.31       608\n",
      "   macro avg       0.31      0.31      0.31       608\n",
      "weighted avg       0.31      0.31      0.31       608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_norm = scaler.fit_transform(training)\n",
    "\n",
    "lg_model = LogisticRegression()\n",
    "\n",
    "lg_model = lg_model.fit(training, t_label)\n",
    "\n",
    "y_pred = lg_model.predict(testing)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c34181c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.30      0.30       124\n",
      "           2       0.27      0.24      0.26       120\n",
      "           3       0.33      0.34      0.33       124\n",
      "           4       0.38      0.42      0.40       120\n",
      "           5       0.28      0.27      0.27       120\n",
      "\n",
      "    accuracy                           0.31       608\n",
      "   macro avg       0.31      0.31      0.31       608\n",
      "weighted avg       0.31      0.31      0.31       608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(training)\n",
    "lg_model = LogisticRegression()\n",
    "lg_model = lg_model.fit(training, t_label)\n",
    "y_pred = lg_model.predict(testing)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "48f421e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.32      0.32       124\n",
      "           2       0.40      0.25      0.31       120\n",
      "           3       0.31      0.39      0.34       124\n",
      "           4       0.45      0.47      0.46       120\n",
      "           5       0.33      0.33      0.33       120\n",
      "\n",
      "    accuracy                           0.35       608\n",
      "   macro avg       0.36      0.35      0.35       608\n",
      "weighted avg       0.36      0.35      0.35       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(training)\n",
    "svm_model = svm_model.fit(training, t_label)\n",
    "y_pred = svm_model.predict(testing)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0d0fd4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.35      0.31       124\n",
      "           2       0.25      0.38      0.30       120\n",
      "           3       0.61      0.09      0.15       124\n",
      "           4       0.24      0.52      0.33       120\n",
      "           5       0.00      0.00      0.00       120\n",
      "\n",
      "    accuracy                           0.26       608\n",
      "   macro avg       0.28      0.27      0.22       608\n",
      "weighted avg       0.28      0.26      0.22       608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(training, t_label)\n",
    "y_pred = knn_model.predict(testing)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1b30546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.03      0.06       124\n",
      "           2       0.25      0.20      0.22       120\n",
      "           3       0.67      0.02      0.03       124\n",
      "           4       0.21      0.88      0.34       120\n",
      "           5       0.00      0.00      0.00       120\n",
      "\n",
      "    accuracy                           0.22       608\n",
      "   macro avg       0.34      0.23      0.13       608\n",
      "weighted avg       0.34      0.22      0.13       608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_model.fit(training, t_label)\n",
    "y_pred = knn_model.predict(testing)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "15e0489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.03      0.06       124\n",
      "           2       0.25      0.20      0.22       120\n",
      "           3       0.67      0.02      0.03       124\n",
      "           4       0.21      0.88      0.34       120\n",
      "           5       0.00      0.00      0.00       120\n",
      "\n",
      "    accuracy                           0.22       608\n",
      "   macro avg       0.34      0.23      0.13       608\n",
      "weighted avg       0.34      0.22      0.13       608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_norm = scaler.fit_transform(training)\n",
    "sgdr = SGDRegressor(max_iter=1000000)\n",
    "sgdr.fit(training, t_label)\n",
    "y_pred_sgd = sgdr.predict(testing)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0350b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sassa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48519736842105265"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "model = VotingClassifier(estimators=[('svm',svm_model),('knn',knn_model),('lr',lg_model),('rf',nb_model)],voting='hard')\n",
    "model.fit(training,t_label)\n",
    "model.score(testing,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def90897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374a1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
